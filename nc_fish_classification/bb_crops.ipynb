{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nature Conservancy Fish Classification - Bounding Box Crops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports & Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import ujson as json\n",
    "import PIL\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from glob import glob\n",
    "from collections import defaultdict\n",
    "\n",
    "ROOT_DIR = os.getcwd()\n",
    "DATA_HOME_DIR = ROOT_DIR + '/data'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# paths\n",
    "data_path = DATA_HOME_DIR + '/' \n",
    "full_train_path = data_path + 'train_full/'\n",
    "crop_path = data_path + 'cropped/'\n",
    "\n",
    "# data\n",
    "classes = [\"ALB\", \"BET\", \"DOL\", \"LAG\", \"OTHER\", \"SHARK\", \"YFT\"]\n",
    "nb_classes = len(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cropping Images to Bounding Box Coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, because a few fish have been relabeled in the training set, the classes won't line up exactly with the classes in the annotation files. \n",
    "\n",
    "As a roundabout way of getting around this, I create a dictionary mapping image files with their respective classes so that when I iterate through the annotation files I can pair them up on the fly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Records: 3777\n"
     ]
    }
   ],
   "source": [
    "class_dict = defaultdict(str)\n",
    "\n",
    "for fp in glob(full_train_path + '*/*g'):\n",
    "    cls = fp.split('/')[-2]\n",
    "    im = fp.split('/')[-1]\n",
    "    class_dict[im] = cls\n",
    "    \n",
    "print(\"Image Records:\", len(class_dict.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load bounding box data from json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "anno_classes = ['alb', 'bet', 'dol', 'lag', 'other', 'shark', 'yft']\n",
    "bb_json = {}\n",
    "\n",
    "for c in anno_classes:\n",
    "    j = json.load(open('bb_annotations/{}.json'.format(c), 'r'))\n",
    "    for l in j:\n",
    "        if 'annotations' in l.keys() and len(l['annotations'])>0:\n",
    "            bb_json[l['filename'].split('/')[-1]] = sorted(\n",
    "                l['annotations'], key=lambda x: x['height']*x['width'])[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function for converting coordinates to resized image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bb_params = ['height', 'width', 'x', 'y']\n",
    "def convert_bb(bb):\n",
    "    cropsize = 224\n",
    "    size = bb[\"size\"]\n",
    "    bb = [bb[p] for p in bb_params]\n",
    "    \n",
    "    # conversion factors\n",
    "    conv_x = (640. / size[0])\n",
    "    conv_y = (360. / size[1])\n",
    "    \n",
    "    # make the size conversions\n",
    "    width, height = size[0]*conv_x, size[1]*conv_y\n",
    "    x = bb[2]*conv_x\n",
    "    y = bb[3]*conv_y\n",
    "    \n",
    "    # offset/padding adjustments\n",
    "    x = max(x - 10, 0)\n",
    "    y = max(y - 10, 0)\n",
    "    \n",
    "    if x + cropsize > width:\n",
    "        x = width - cropsize\n",
    "    if y + cropsize > height:\n",
    "        y = height - cropsize\n",
    "    \n",
    "    bb[0] = cropsize\n",
    "    bb[1] = cropsize\n",
    "    bb[2] = x\n",
    "    bb[3] = y\n",
    "    return bb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we iterate through each class, grab the annotations for that class, crop the image down to a square around the fish, and save it to my cropped data directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "j = json.load(open('bb_annotations/{}.json'.format(c.lower()), 'r'))\n",
    "\n",
    "for c in classes:\n",
    "    fns = glob(full_train_path + c + '/*.jpg')\n",
    "    \n",
    "    for fn in fns:\n",
    "        f_id = fn.split(\"/\")[-1]\n",
    "        cls = class_dict[f_id]\n",
    "        im = PIL.Image.open('{0}{1}/{2}'.format(full_train_path, cls, f_id))\n",
    "        width, height = im.size\n",
    "    \n",
    "        if not f_id in bb_json.keys():\n",
    "            continue\n",
    "#             x = random.uniform(0, width)\n",
    "#             y = random.uniform(0, height)\n",
    "#             bb = {\"height\": 0, \"width\": 0, \"x\": x, \"y\": y, \"size\": im.size}\n",
    "#             bb = convert_bb(bb)\n",
    "#             im = im.resize((640, 360))\n",
    "#             cropped = im.crop((bb[2], bb[3], bb[2] + bb[1], bb[3] + bb[0]))\n",
    "#             cropped.save(fn.replace(full_train_path, crop_path)) \n",
    "        else:\n",
    "            anno = bb_json[f_id]\n",
    "            x, y = anno[\"x\"], anno[\"y\"]\n",
    "            bb = {\"height\": 0, \"width\": 0, \"x\": x, \"y\": y, \"size\": im.size}\n",
    "            bb = convert_bb(bb)\n",
    "            im = im.resize((640, 360))\n",
    "            cropped = im.crop((bb[2], bb[3], bb[2] + bb[1], bb[3] + bb[0]))\n",
    "            cropped.save(fn.replace(full_train_path, crop_path)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cropped Image Records: 3297\n"
     ]
    }
   ],
   "source": [
    "crops = glob(crop_path + '*/*g')\n",
    "\n",
    "print(\"Cropped Image Records:\", len(crops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like a few records were lost in the process (in addition to the ones printed out above), but after looking through some of the missing annotations, there's generally a good reason, such as multiple fish or obscured fish. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
